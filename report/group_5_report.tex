\documentclass[12pt]{article}

\usepackage{geometry}
\usepackage{cite}
\usepackage{graphicx}

\geometry{margin=1in}

\bibliographystyle{plain}

\begin{document}
\large\center\textbf{Implementing Similarity Network Creation in Neo4J}\\
\normalsize\center{Evan Stene, Bahavana, Sumanth, Thrupthi}

\flushleft
\section*{Problem Statement and Background}
\quad The Similarity Network Fusion (SNF) is a powerful technique for clustering medical patients utilizing a variety of data types in order to assist in diagnosing diseases such as cancer. Each patient is associated with a wide range of data from a variety of medical tests. The results of each test can, as a whole, be considered a separate data type, and patients can be measured according to a specific data type to form a similarity network. Networks spanning multiple data types can then be combined through iterative fusion steps to form a single network that captures the overall similarity between patients in the network. Given the nature of medical data, patients should be clustered according to certain attributes from their test data assuming that those in a cluster have received a similar diagnosis. The goal for SNF is twofold: identify the defining attributes for each cluster, and place new patients into appropriate clusters in order to assign them a possible diagnosis.\\
\quad SNF is useful for data with a very low ratio of samples to features, which is true of medical data that spans multiple data types. Data of this nature tends to produce a low signal to noise ratio in analysis, a problem that affects the predictive power of the model.\\
\quad Currently, the method for creating an SNF requires using a mathematical or statistical modeling language such as MATLAB or R. We believe that this approach lacks the ability to scale to larger datasets both in terms of creation time of the network and in providing a framework for querying the network. Our goal was to implement the SNF creation in the native graph database application Neo4J. Our belief was that doing so would enable smarter access to the disk so that operations could be done efficiently even when the data will not fit in memory. On top of that, we wanted to provide a framework for implementing queries in the future that could be run on the SNF sitting on the database, something not implemented in the existing methods.\\

\section*{Related Works}
\quad SNF provides a framework for discovering mechanisms responsible for diseases, clustering or sub-typing samples (patients), and predicting outcomes (survival). There are other strategies that attempt to achieve one or more of these goals, but each has drawbacks that prevent it from working with the same success as SNF.\\
\subsection*{Independent Analysis}
\quad Although possible to analyze each attribute independently, this is time intensive and inconsistent.
\subsection*{Feature Concatenation}
\quad Another strategy is to simply concatenate each data type into a single feature list before performing traditional clustering techniques. However, when data is producing a low signal to noise ratio, lengthening the feature list only serves to exacerbate the problem. 
\subsection*{Gene Preselection}
\quad Genes known to be important may also be preselected before analysis to identify which are effected in each subtype. This strategy is biased toward existing knowledge and does not facilitate new gene exploration or possible interactions between multiple effected areas.

\section*{Solution}
\quad Our method is based on the SNF implementation method described in \cite{snf-nat}. The original implementation written by the authors of the paper is available at http://compbio.cs.toronto.edu/SNF/SNF/Software.html and is provided in both MATLAB and R formats, each containing the necessary code to build the network and provide some statistical analysis on the result. Data for five different diseases, each spanning three data types for around 200 patients, was also supplied on the website and is the data used by the authors of \cite{snf-nat}.\\
\quad Our work is an attempt to expand the SNF for use with higher volumes of data by implementing the network as a graph database. As more and more data is becoming available, the SNF must be able to adapt to much larger sample sizes or conversely, to generate the transpose SNF where features are clustered rather than samples.\\

\section*{Results}
\quad Our method was meant to be tested against the existing method implemented in MATLAB based on runtime only. The time would be limited to the time taken in order to create a single similarity network (without any fusion and on only a single data type) on both the original implementation and our own. However, because the MATLAB solution is able to work entirely in local memory, our database method suffers from overhead of disk I/O and maintenance by Neo4j. The advantage our method brings is only when the data becomes very large such that it cannot be operated on in a single matrix sitting in memory. In such a case MATLAB will simply throw an error stating that it has run out of memory. Therefore, our comparison based on time is only on data sets giving our implementation a disadvantage, but show the trend towards scalability without increasing run time at a higher rate than MATLAB such that we can assume a truly large data set will be built in optimal time on our implementation.
\begin{figure}
	\caption{Time required to build a single fusion network for differing orders of patient numbers.}
\end{figure}

\section*{Conclusion and Future Work}
\quad Unfortunately, due to time constraints, we were not able to explore every optimization to our method in order to truly give it an edge against the existing method for anything but very large datasets. However, below are some topics that could be worth considering in the future.
\subsection*{Fusion}
The final step in the existing method of SNF is to fuse the multiple similarity networks created for each data type into a single network. Our method omits this step as creating the initial similarity networks were challenging enough in their own right and more research would have been needed to implement fusion for little additional insight. However, for the sake of completeness, this is an obvious first step for further expansion.
\subsection*{Parallelism}
\quad Computing initial distances among nodes and similarity from that is independent amongst nodes in the sense that, from a single nodes perspective, a subgraph of a single node and its connections is independent from a similar network at any other node in the network with the exception of the single edge connecting the two nodes in question. This is important because computing similarity involves calculating the mean distance of all edges connected to a node and means similarity between two nodes should be possible to make parallel. Each subgraph  can be averaged in parallel given that all edges in a subgraph can be queried from the database in parallel as read-only operations and calculated without relying on any information from other subgraphs. Other aspects of the SNF creation may be possible to parallelize, but this is a small example based on our observations.
\subsection*{Clusters and Statistics}
\quad Once the similarities of the nodes have been computed, defining the number and members of each resulting cluster is critical to the usefulness of the SNF. Having some way of defining queries to run on top of our database could aid in \\
\quad Our solution attempts to go one step further by adding feature recognition in order to define a most probable identifying data pattern for a cluster. Having the knowledge of possible indicators for subtypes would not only be useful information for researchers, but also for implementing further network queries.
\subsection*{Insert Queries}
\quad Inserting new patients into the network is difficult to implement efficiently because new patients could potentially have similarity to any of the existing members of the network. Assigning a patient to a cluster could require comparing every attribute among every existing patient to define new similarities. However, with the addition of recognized features for each cluster, it may be possible to only compare a select few features at first to identify a cluster then focus on similarity only to other patients in that cluster. 
\section*{Team Contributions}
The following break down has been agreed to by each member of the team.
\subsection*{Evan Stene - 25\%}
\quad Wrote the bulk of the Python code that loaded the database and created the similarity network. Wrote a portion of the final report.
\subsection*{Bhavana - 25\%}
\quad Gathered and cleaned data used in testing the code and contributed code to the main Python project including testing.
\subsection*{Thrupthi - 25\%}
\quad Worked on presentations
\subsection*{Sumanth - 25\%}
\quad Worked on presentations

\bibliography{snf-nature}
\end{document}


